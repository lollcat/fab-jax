flow:
  n_layers: 8
  conditioner_mlp_units: [80, 80]
  act_norm: False

fab:
  alpha: 2.  # alpha-divergence param
  use_kl_loss: false # additional KL loss.
  w_adjust_clip: 10.
  smc:
    use_resampling: false
    n_intermediate_distributions: 2
    spacing_type: linear
    transition_operator: metropolis # [hmc or metropolis]
    hmc:
      n_outer_steps: 1
      n_inner_steps: 5
      init_step_size: 1e-2
      target_p_accept: 0.65
      tune_step_size: true
    metropolis:
      n_outer_steps: 1
      init_step_size: 1.  # Needs to be big enough to jump between modes
      target_p_accept: 0.65
      tune_step_size: false
  buffer:
    with_buffer: True
    buffer_max_length_in_batches: 400
    buffer_min_length_in_batches: 40
    n_updates_per_smc_forward_pass: 4


training:
  optimizer:
      lr: 1e-3
      dynamic_grad_ignore_and_clip: true
  n_epoch: 1000
  batch_size: 128
  eval_batch_size: 2_000
  plot_batch_size: 1_000
  use_64_bit: true
  seed: 0
  n_checkpoints: 0
  n_eval: 20


#logger:
##  list_logger: null
##  pandas_logger:
##    save_period: 1000 # how often to save the pandas dataframe as a csv
#  wandb:
#    name: dw4_${flow.type}_${training.train_set_size}
#    project: fab
#    entity: flow-ais-bootstrap
#    tags: [dw4,ml,protea]